{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi8yXoiIwwqL"
      },
      "source": [
        "# LOG6308\n",
        "# TP3 : Systèmes de recommandation et réseaux de neurones\n",
        "\n",
        "L'objectif du TP3 est de vous familiariser avec la librairie `Tensorflow` et `Tensorflow Recommenders`. Nous souhaitons aussi vous familiariser avec le concept de réseaux neuronaux.\n",
        "C'est pourquoi nous vous proposons d'effectuer des recommandations de films sur la base de données que vous connaissez bien maintenant : [MovieLens 100k](https://grouplens.org/datasets/movielens/).<br>\n",
        "\n",
        "Le TP sera noté **sur 100**.\n",
        "\n",
        "## Critères de correction\n",
        "\n",
        "- Démarche valide et bien expliquée\n",
        "- Réponses correctes et commentées\n",
        "- Présentation soignée \n",
        "- Choix de fonctionnalités adéquat\n",
        "- Interprétation étayée des résultats\n",
        "\n",
        "## Instructions Globales\n",
        "\n",
        "Le travail doit être fait en **équipe de deux**.\n",
        "\n",
        "Vous avez le droit d'utiliser **seulement** les **librairies importées** pour résoudre les **questions 1, 2 et 3**. Si vous utilisez d’autres librairies, vos réponses ne seront pas considérées.\n",
        "\n",
        "Vous pouvez répondre aux sous-questions en commentaire ou dans des cellules textes en prenant bien soin d’identifier à quelle question vous répondez.\n",
        "Ceux qui le souhaite peuvent développer en local et écrire votre code dans des fichiers Python en `.py`. Ceci dit, j'attends de vous un README.md m'expliquant comment exécuter votre code avec une liste de dépendances (Requirements).\n",
        "\n",
        "Pour les questions 1-2-3, le Notebook est suffisant. Vous pouvez marquer vos commentaires et réponses qualitatives dans des cellules textes. \n",
        "Par contre, pour la question 4, il est recommandé de fournir un rapport séparé du code en format PDF. Mais, si vous ne souhaitez pas rédiger de rapport, vous pouvez rédiger votre état de l’art et votre démarche dans des cellules textes du Notebook sur Colab.\n",
        "\n",
        "\n",
        "Pour la remise du travail sur Moodle, on s’attend à un Zip qui contient un notebook en `.ipynb` et/ou des fichiers Python en `.py`. **Si vous décidez** de **rédiger un rapport** pour la **question 4**, vous devez alors aussi **inclure** un fichier **PDF**. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQGIsPAV3XZu"
      },
      "source": [
        "### Comment télécharger le notebook\n",
        "\n",
        "- Cliquez sur le menu \"Fichier\" (*File* en anglais) dans le coin supérieur gauche.\n",
        "- Une fenêtre popup apparaît, trouvez `Télécharger -> Télécharger le fichier .ipynb` et cliquez dessus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIyu9ymF7loQ"
      },
      "source": [
        "#### Installation de tensorflow datasets, tensorflow recommenders, et importation des librairies requises pour le TP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iUJAKyxxAA-h",
        "outputId": "7f164548-bd8c-48cc-beb5-9b83f849e00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.5.2.dev202204150045-py3-none-any.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (2.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.0.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (0.3.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.21.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.15.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (2.23.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.7.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (1.1.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (5.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (4.1.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from tfds-nightly) (3.17.3)\n",
            "Collecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting etils[epath-no-tf]\n",
            "  Downloading etils-0.5.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->tfds-nightly) (2.10)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath-no-tf]->tfds-nightly) (3.8.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tfds-nightly) (1.56.0)\n",
            "Installing collected packages: etils, toml, tfds-nightly\n",
            "Successfully installed etils-0.5.0 tfds-nightly-4.5.2.dev202204150045 toml-0.10.2\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 45.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 9.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 8.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tfds-nightly\n",
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets==4.3\n",
        "!pip install -q scann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t5Mylp7CACnE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from tqdm import tqdm\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow_recommenders as tfrs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbEAcYCo3quT"
      },
      "source": [
        "## Utilisation du GPU\n",
        "Les calculs seront plus rapides si vous utilisez le GPU. Ça sera particulièrement important pour la dernière partie. Pour s'assurer que le notebook utilise le GPU, vous pouvez modifier la configuration ainsi :\n",
        "* (EN) `Edit > Notebook Settings`\n",
        "* (FR) `Modifier > Paramètres du notebook`\n",
        "\n",
        "Par contre, faites attention à ne pas utiliser le GPU si vous n'en avez pas besoin. Colab limite le temps d'utilisation des GPUs pour sa version gratuite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "p1o11-QT8-s9",
        "outputId": "e24abbe9-532b-4807-cf67-d38bddc521bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vous utilisez actuellement le GPU\n"
          ]
        }
      ],
      "source": [
        "#Test CPU ou GPU\n",
        "if(len(tf.config.list_physical_devices('GPU')) == 0):\n",
        "    print(\"Vous utilisez actuellement le CPU\")\n",
        "else:\n",
        "    print(\"Vous utilisez actuellement le GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X51rl6S_7uyy"
      },
      "source": [
        "#### Téléchargement de MovieLens 100k\n",
        "\n",
        "Vous pouvez accéder à la documentation en appuyant sur ce [lien](https://www.tensorflow.org/datasets/catalog/movielens#movielens100k-ratings)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "collapsed": true,
        "id": "zpXu3gy0AIqY"
      },
      "outputs": [],
      "source": [
        "# Extra code\n",
        "#!unrar x Data.rar\n",
        "movies_df  = pd.read_csv('Data/items.csv', sep='|')\n",
        "ratings_df = pd.read_csv('Data/votes.csv', sep='|')\n",
        "ratings_df = ratings_df.rename(columns={'user.id': 'user_id', 'item.id': 'movie_title', 'rating': 'user_rating', 'timestamp': 'timestamp'})\n",
        "ratings_df = ratings_df.astype('float32')\n",
        "ratings = tf.data.Dataset.from_tensor_slices(tf.cast(ratings_df.values, tf.float32))\n",
        "films = ratings\n",
        "\n",
        "# Les votes + des données supplémentaires\n",
        "##ratings = tfds.load(\"movielens/100k-ratings\", split=\"train\", shuffle_files = False)\n",
        "# Les genres, titres et identifiants des films.\n",
        "##films = tfds.load(\"movielens/100k-ratings\", split=\"train\", shuffle_files = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lkGxv6l6CYrU",
        "outputId": "4051fd5d-9a03-41a8-c887-988c63352c0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#tfds\n",
        "type(ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X3_idfqBzOl"
      },
      "source": [
        "Comme vous le voyez, `ratings` et `films` sont générés par `tfds` et sont des `tf.data.Dataset`. Pour avoir une idée de comment les utilisées, vous pouvez consulter ces liens : <br>\n",
        "- [DataSet](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)\n",
        "- [tfds](https://www.tensorflow.org/datasets/overview)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CiGdoK_iCFeF",
        "outputId": "00b015c7-2943-4f01-a1cd-3f32387d0293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Exemple d'utilisation\n",
        "##list(ratings.map(lambda x: x[\"user_id\"]).take(10))\n",
        "list(ratings.map(lambda x: x[2]).take(10))\n",
        "print(min(ratings.map(lambda x: x[2])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J9HUKr2Gf7a"
      },
      "source": [
        "## Question 1 (15 pts)\n",
        "Dans cette question, nous allons définir et entrainer un modèle dit *Two Tower* afin de prédire les votes selon cette formule :\n",
        "\n",
        "$$pred_{i,j}= b + E_{u_i}^TE_{f_j}.$$\n",
        "\n",
        "\n",
        "Où $(E_{u_i}, E_{f_j}) \\in \\mathbb{R}^n \\times \\mathbb{R}^n$ sont respectivement les plongements (<i>embeddings</i>) de l'utilisateur $i$, $u_i$, et du film $j$, $f_j$. De plus, $b \\in \\mathbb{R}$ est la constante qui représente la moyenne. Enfin, $n \\in \\mathbb{N}$ est respectivement la dimension de l'espace latent des utilisateurs et des films (dans cette question, $n=32$).\n",
        "\n",
        "<br>\n",
        "\n",
        "***Pour répondre aux questions, vous devez remplacer les `?` par les valeurs adéquates.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXC_qIhL8wyX"
      },
      "source": [
        "### 1.1. Extraire les attributs nécessaires pour entrainer le modèle (1 pt)\n",
        "\n",
        "On vous demande d'extraire des données les `titres de films`, les `identifiants utilisateurs`, les `votes`, et les `horodatages` (<i>timestamps</i>). Les données doivent être sous format chaine de caractères (`str`). Voici la [doc](https://www.tensorflow.org/datasets/catalog/movielens#movielens100k-ratings). <br><br>\n",
        "*À modifier si vous voulez inclure d'autres features pour les questions 3 et 4.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ViGKneQPIq_t"
      },
      "outputs": [],
      "source": [
        "#votes = ratings.map(lambda x: {\"?\": x[\"?\"],\"?\": x[\"?\"],\"?\": x[\"?\"], \"?\": tf.strings.as_string(x[\"?\"])})\n",
        "votes = ratings.map(lambda x: {\"movie_title\": tf.strings.as_string(x[1]),\"user_id\": tf.strings.as_string(x[0]), \"user_rating\": x[2], \"timestamp\": x[3]})\n",
        "films = votes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLTYHO8EJ_5v"
      },
      "source": [
        "### 1.2. Statistiques sur les données de `MovieLens 100k`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFzhe1s5KEHz"
      },
      "source": [
        "#### 1.2.a Affichez le nombre d'utilisateurs uniques (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05URFTTVJgQP",
        "outputId": "41baa5c8-5d0c-42e7-d4d0-7cd104de1e9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "943"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Identifiant des utilisateurs\n",
        "id_utilisateurs = votes.map(lambda x: x[\"user_id\"]).batch(1000000)# On prend tous les utilisateurs d'un coup\n",
        "id_uniques      = np.unique(np.concatenate(list(id_utilisateurs)))\n",
        "nb_id_uniques   = id_uniques.shape[0]\n",
        "nb_id_uniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFzgnvQ-KLj-"
      },
      "source": [
        "#### 1.2.b Affichez le nombre de films uniques (1 pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OAIp2eSkKLsg",
        "outputId": "7943c7be-3a1f-4e53-988e-4b585105058a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1682"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#Titres des films\n",
        "titres_films    = films.map(lambda x: x[\"movie_title\"]).batch(1000000)# On prend tous les films d'un coup\n",
        "films_unique    = np.unique(np.concatenate(list(titres_films)))\n",
        "nb_films_unique = films_unique.shape[0]\n",
        "nb_films_unique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqEdoGD6KL31"
      },
      "source": [
        "#### 1.2.c Affichez le nombre de votes et les fréquences de paires (utilisateurs, films) uniques. Constatez-vous des anomalies ? Si oui, quelles sont-elles ? (3 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cee_a332gHVP",
        "outputId": "01bafdbd-a7d6-494e-da8c-08ff2a3fe78e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of votes is 100000\n",
            "The number of unique pairs is 1586126\n",
            "Therefore, we can see that we have a very sparse dataset, with only 6.304669364224531% of possible values present.\n",
            "We either have to treat this sparsity somehow, or create embeddings to encapsulate only the present values.\n"
          ]
        }
      ],
      "source": [
        "## Number of votes\n",
        "number_of_votes = len(votes)\n",
        "print(\"The number of votes is {}\".format(number_of_votes))\n",
        "## Unique pairs\n",
        "unique_pairs = nb_id_uniques * nb_films_unique\n",
        "print(\"The number of unique pairs is {}\".format(unique_pairs))\n",
        "print(\"Therefore, we can see that we have a very sparse dataset, with only {}% of possible values present.\".format((number_of_votes/unique_pairs)*100))\n",
        "print(\"We either have to treat this sparsity somehow, or create embeddings to encapsulate only the present values.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD5AjtAfJhCB"
      },
      "source": [
        "### 1.3. Initialisation de la metrique RMSE de tfrs (1 pt)\n",
        "\n",
        "Soit $y\\in \\mathbb{R}^N$ un vecteur de valeur de votes issue de la base de données d'entrainement, et $\\hat{y} \\in \\mathbb{R}^N$ la prédiction de ces votes par notre modèle. Pour que notre modèle soit performant, nous aimerions bien que $\\hat{y}$ ait quasiment les mêmes valeurs que $y$. On cherche donc à minimiser la perte suivante, qui est la **MSE** (*Mean Square Error*) :\n",
        "\n",
        "<br>\n",
        "\n",
        "$$\\boxed{l(\\hat{y}, y) = ||\\hat{y}-y||_2^2 = \\cfrac{1}{N}\\underset{i=1}{\\overset{N}{\\sum }}|\\hat{y} - y|^2}.$$\n",
        "\n",
        "<br>\n",
        "\n",
        "Initialisez la tâche avec la perte adéquate en utilisant `tfrs.tasks.Ranking`, voici la [doc](https://www.tensorflow.org/recommenders/api_docs/python/tfrs/tasks/Ranking). Il faut donc utiliser `tf.keras.losses.MeanSquaredError()` comme **perte**, et `tf.keras.metrics.RootMeanSquaredError()` comme **métrique**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wk5le5DAJgUf"
      },
      "outputs": [],
      "source": [
        "task = tfrs.tasks.Ranking(loss = tf.keras.losses.MeanSquaredError(), metrics = [tf.keras.metrics.RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAFp2Qq8O0-Q"
      },
      "source": [
        "### 1.4. Définition du modèle Two Towers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGrNtpwDQc5X"
      },
      "source": [
        "#### 1.4.1. On définit la dimension de l'espace latent (taille des plongements) comme étant égale à 32. Pourquoi ne pas avoir choisi une dimension plus élevée ? (1 pt)<br>\n",
        "\n",
        "<u>Réponse</u> :<br>\n",
        "Embedding words in a high dimension space requires more data to enforce density and significance of the representation, becoming hard to compute and converge in high dimensional spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCrYSMNDQ1qY"
      },
      "outputs": [],
      "source": [
        "embedding_dimension = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIrlqfBZQ2hd"
      },
      "source": [
        "#### 1.4.2. Définir les couches de plongement pour les utilisateurs et les films (1 pt)\n",
        "\n",
        "Pour initaliser les espaces de plongements, vous pouvez vous aider de la documentation de [tf.keras.layers.Embedding](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding).<br>\n",
        "\n",
        "Pour comprendre `tf.keras.layers.experimental.preprocessing.StringLookup`, aidez-vous de la [doc](https://www.tensorflow.org/api_docs/python/tf/keras/layers/StringLookup)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjVKI9T7Q2zf"
      },
      "outputs": [],
      "source": [
        "def initialisation_embeddings(embedding_dimension, id_uniques, films_unique):\n",
        "    user_model = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=id_uniques, mask_token=None),\n",
        "                                    tf.keras.layers.Embedding(len(id_uniques) + 1,# Le +1 représente la constante $c$\n",
        "                                                                embedding_dimension)], name=\"User_Embedding\")\n",
        "\n",
        "    movie_model = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=films_unique,mask_token=None),\n",
        "                                    tf.keras.layers.Embedding(len(films_unique) + 1, \n",
        "                                                                embedding_dimension)], name=\"Movie_Embedding\")  \n",
        "    return user_model, movie_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06nJZzs4Uivf"
      },
      "source": [
        "#### 1.4.3. Assemblez le modèle *Two Towers* (2 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8STmaQyWO0MX"
      },
      "outputs": [],
      "source": [
        "class MovieLensModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, embedding_dimension, id_uniques, films_unique, task):\n",
        "    super().__init__()\n",
        "    self.user_model, self.movie_model = initialisation_embeddings(embedding_dimension, id_uniques, films_unique)\n",
        "    \n",
        "    self.pred = tf.keras.layers.Dot(axes=1)\n",
        "    \n",
        "    self.task: tf.keras.layers.Layer = task\n",
        "\n",
        "  def call(self, features):\n",
        "    user_embedding, movie_embedding = self.user_model(features[\"user_id\"]), self.movie_model(features[\"movie_title\"]) ## Embeddings extraction\n",
        "    votes_predictions = self.pred([user_embedding, movie_embedding]) ## Scalar product of the two embeddings\n",
        "    return votes_predictions\n",
        "  \n",
        "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
        "    \n",
        "    return self.task(labels=features[\"user_rating\"], predictions=self.call(features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m1Y-ELtVo4L"
      },
      "source": [
        "### 1.5. Entrainement du modèle\n",
        "Dans cette partie, on entraine et test le modèle defini au dessus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wXJezITRCGk"
      },
      "source": [
        "#### Définir les bases de données d'entrainement et de validation (proportion $80\\%-20\\%$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0ZI0GidMW9ju"
      },
      "outputs": [],
      "source": [
        "N          = len(votes)\n",
        "batch_size = 8192 #2^13\n",
        "prop       = 0.8\n",
        "train_len  = tf.cast(N * prop, dtype=tf.int64)\n",
        "valid_len   = tf.cast(N - train_len, dtype=tf.int64)\n",
        "\n",
        "\n",
        "# shuffled = votes.shuffle(N, seed=73, reshuffle_each_iteration=False)\n",
        "\n",
        "tf.random.set_seed(73)\n",
        "train = votes.take(train_len).shuffle(train_len, seed=73, reshuffle_each_iteration=False).batch(batch_size)\n",
        "valid = votes.skip(train_len).take(valid_len).shuffle(valid_len, seed=73, reshuffle_each_iteration=False).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsmpzsWYa_kU"
      },
      "source": [
        "#### 1.5.1. Initialisez le modèle, l'optimiseur et les modules de callback pour l'entrainement (2 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "86HwCAJoiJxh",
        "outputId": "3a8cd5fe-d58a-4de2-b987-af491112d7a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'movie_title': <tf.Tensor: shape=(8192,), dtype=string, numpy=\n",
              " array([b'879.000000', b'882.000000', b'475.000000', ..., b'403.000000',\n",
              "        b'451.000000', b'518.000000'], dtype=object)>,\n",
              " 'timestamp': <tf.Tensor: shape=(8192,), dtype=float32, numpy=\n",
              " array([8.7956160e+08, 8.8818003e+08, 8.7564013e+08, ..., 8.8015149e+08,\n",
              "        8.9103603e+08, 8.8491648e+08], dtype=float32)>,\n",
              " 'user_id': <tf.Tensor: shape=(8192,), dtype=string, numpy=\n",
              " array([b'459.000000', b'206.000000', b'92.000000', ..., b'653.000000',\n",
              "        b'210.000000', b'345.000000'], dtype=object)>,\n",
              " 'user_rating': <tf.Tensor: shape=(8192,), dtype=float32, numpy=array([4., 1., 5., ..., 2., 3., 4.], dtype=float32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# On tire un exemple pour construire le graphe du modèle\n",
        "feature = next(iter(train))\n",
        "feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "N0pn6SPTghMQ",
        "outputId": "401088b3-409d-461f-a65a-2ac8e798ccd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"movie_lens_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " User_Embedding (Sequential)  (8192, 32)               30208     \n",
            "                                                                 \n",
            " Movie_Embedding (Sequential  (8192, 32)               53856     \n",
            " )                                                               \n",
            "                                                                 \n",
            " dot (Dot)                   multiple                  0         \n",
            "                                                                 \n",
            " ranking (Ranking)           multiple                  0 (unused)\n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,064\n",
            "Trainable params: 84,064\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# On construit et affiche le modèle\n",
        "Model = MovieLensModel(embedding_dimension, id_uniques, films_unique, task)\n",
        "Model(feature)\n",
        "Model.summary() # comment expliquez-vous le nombre de paramètres des couches embeddings ? (32*x, where x is the number of unique values of each variable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R2s3ownsuPh"
      },
      "source": [
        "On utilise comme optimiseur `Adam` (voir la [doc](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)) qui prend $0.01$ comme valeur pour son `learning_rate`. On vous demande aussi d'utiliser la stratégie *early stopping* pour entrainer votre modèle (voir les explications [ici](https://www.educative.io/edpresso/what-is-early-stopping)). Cette stratégie est implémentée par `Keras` comme un module *callback*, voir la [doc](https://keras.io/api/callbacks/). La **patience** doit être égale à $3$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13XVbRv-gh-R"
      },
      "outputs": [],
      "source": [
        "# Création du dossier contenant les modèles entrainés\n",
        "#!mkdir Models/\n",
        "\n",
        "# Compiler le modèle en ajoutant l'optimiseur Adam\n",
        "Model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01))\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AaXK27Rla_nI"
      },
      "source": [
        "#### 1.5.2. Entrainez le modèle sur **15 epochs** et afficher les résultats ainsi que la meilleure **RMSE** sur l'ensemble de validation. Y a-t-il surapprentissage ? (2 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hQiWAXEEjshI",
        "outputId": "ee75c7f1-5785-4b9c-e39c-a3fad7532296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "10/10 [==============================] - 10s 516ms/step - root_mean_squared_error: 3.7021 - loss: 13.6748 - regularization_loss: 0.0000e+00 - total_loss: 13.6748 - val_root_mean_squared_error: 3.6652 - val_loss: 13.4904 - val_regularization_loss: 0.0000e+00 - val_total_loss: 13.4904\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 12s 980ms/step - root_mean_squared_error: 3.5504 - loss: 12.4440 - regularization_loss: 0.0000e+00 - total_loss: 12.4440 - val_root_mean_squared_error: 3.3131 - val_loss: 11.0178 - val_regularization_loss: 0.0000e+00 - val_total_loss: 11.0178\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 8s 526ms/step - root_mean_squared_error: 2.9051 - loss: 8.1185 - regularization_loss: 0.0000e+00 - total_loss: 8.1185 - val_root_mean_squared_error: 2.3013 - val_loss: 5.2993 - val_regularization_loss: 0.0000e+00 - val_total_loss: 5.2993\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 8s 515ms/step - root_mean_squared_error: 1.6890 - loss: 2.6791 - regularization_loss: 0.0000e+00 - total_loss: 2.6791 - val_root_mean_squared_error: 1.1571 - val_loss: 1.2983 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2983\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 8s 517ms/step - root_mean_squared_error: 1.1422 - loss: 1.3105 - regularization_loss: 0.0000e+00 - total_loss: 1.3105 - val_root_mean_squared_error: 1.1496 - val_loss: 1.2904 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2904\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 8s 524ms/step - root_mean_squared_error: 1.0245 - loss: 1.0271 - regularization_loss: 0.0000e+00 - total_loss: 1.0271 - val_root_mean_squared_error: 0.9722 - val_loss: 0.9467 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9467\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 8s 506ms/step - root_mean_squared_error: 0.9413 - loss: 0.8831 - regularization_loss: 0.0000e+00 - total_loss: 0.8831 - val_root_mean_squared_error: 0.9804 - val_loss: 0.9672 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9672\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 8s 509ms/step - root_mean_squared_error: 0.9192 - loss: 0.8389 - regularization_loss: 0.0000e+00 - total_loss: 0.8389 - val_root_mean_squared_error: 0.9513 - val_loss: 0.8954 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8954\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 8s 524ms/step - root_mean_squared_error: 0.9021 - loss: 0.8110 - regularization_loss: 0.0000e+00 - total_loss: 0.8110 - val_root_mean_squared_error: 0.9492 - val_loss: 0.8886 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8886\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 8s 517ms/step - root_mean_squared_error: 0.8936 - loss: 0.7950 - regularization_loss: 0.0000e+00 - total_loss: 0.7950 - val_root_mean_squared_error: 0.9434 - val_loss: 0.8843 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8843\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 8s 514ms/step - root_mean_squared_error: 0.8862 - loss: 0.7818 - regularization_loss: 0.0000e+00 - total_loss: 0.7818 - val_root_mean_squared_error: 0.9415 - val_loss: 0.8812 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8812\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 10s 723ms/step - root_mean_squared_error: 0.8787 - loss: 0.7684 - regularization_loss: 0.0000e+00 - total_loss: 0.7684 - val_root_mean_squared_error: 0.9392 - val_loss: 0.8750 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8750\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 8s 512ms/step - root_mean_squared_error: 0.8712 - loss: 0.7551 - regularization_loss: 0.0000e+00 - total_loss: 0.7551 - val_root_mean_squared_error: 0.9371 - val_loss: 0.8721 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8721\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 8s 517ms/step - root_mean_squared_error: 0.8632 - loss: 0.7410 - regularization_loss: 0.0000e+00 - total_loss: 0.7410 - val_root_mean_squared_error: 0.9352 - val_loss: 0.8702 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8702\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 8s 510ms/step - root_mean_squared_error: 0.8549 - loss: 0.7265 - regularization_loss: 0.0000e+00 - total_loss: 0.7265 - val_root_mean_squared_error: 0.9336 - val_loss: 0.8679 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8679\n"
          ]
        }
      ],
      "source": [
        "#Entrainement du modèle sur 15 epochs\n",
        "history_TwoTowers = Model.fit(train, epochs=15, validation_data=valid, callbacks=my_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "574bL-vDkGiS",
        "outputId": "687e4707-8627-4318-b7c3-61cc13bfd348"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Best RMSE on validation : 0.9336\n"
          ]
        }
      ],
      "source": [
        "def plot_history(history, model_name=\"Two Towers\"):\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['root_mean_squared_error'])\n",
        "    plt.plot(history.history['val_root_mean_squared_error'])\n",
        "    plt.title(model_name + ' Model RMSE')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.show()\n",
        "    print(\"\\n\\nBest RMSE on validation : {0:.4f}\".format(min(history.history['val_root_mean_squared_error'])))\n",
        "\n",
        "plot_history(history_TwoTowers, model_name=\"Two Towers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b5Zn9sw_LAw"
      },
      "source": [
        "L'overfitting n'a pas lieu de manière flagrande pendant les 15 premières epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwSZ9vowcBmX"
      },
      "source": [
        "## Question 2 (15 pts)\n",
        "\n",
        "Modifier le modèle Two Tower pour prendre en compte le biais utilisateur et item (film). La nouvelle formule de prédiction est donc :\n",
        "\n",
        "$$pred_{i,j}= \\sigma(b + biais_{u_i} + biais_{f_j} +E_{u_i}^TE_{f_j}) \\times (M_{vote} - m_{vote}) + m_{vote}$$\n",
        "\n",
        "<br>\n",
        "\n",
        "Où $biais_{u_i} \\in \\mathbb{R}$ est le biais associé à l'utilisateur $u_i$ et $biais_{f_j} \\in \\mathbb{R}$ le biais associé au film $f_j$. <br>\n",
        "\n",
        "$\\sigma: x \\mapsto \\cfrac{1}{1+e^{-x}}$ est la fonction sigmoid, elle est déjà implémentée par TensorFlow : `tf.math.sigmoid`.<br>\n",
        "\n",
        "Et, $M_{vote}, m_{vote}$ sont respectivement le maximum et le minimum des votes utilisateurs. Dans notre cas, $M_{vote}=5$ et $m_{vote}=1$.\n",
        "\n",
        "### Description du modèle Two Tower avec Biais\n",
        "\n",
        "Le modèle Keras correspondant est légèrement plus complexe. En plus des plongements d'utilisateurs et de films avec lesquelles nous avons déjà travaillé, le modèle ci-dessous approxime le biais utilisateur ($biais_{u_i}$) et le biais film ($biais_{f_j}$) en plongeant l'utilisateur et le film dans un espace unidimensionnel. Nous ajoutons ensuite les deux biais au produit scalaire représentant l'interaction utilisateur-film. La fonction d'activation sigmoïde normalise et ramène la prédiction à l'intervalle $[0,1]$, qui est ensuite ramenée à l'intervalle de vote original $[m_{vote}, M_{vote}]$. D'ailleurs, le dropout doit être appliqué aux sorties des couches `user_model` et `movie_model`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "331CwGWJHdhs"
      },
      "source": [
        "### Définissez, initialisez, entrainez, affichez et interprétez les résultats du modèle Two Tower modifié. Y a-t-il surapprentissage ?\n",
        "\n",
        "Dans cette question, il vous ai conseillé d'utiliser Adam avec un `learning_rate`$=0.005$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRkKTjY_cgRZ"
      },
      "outputs": [],
      "source": [
        "#MovieLensModelWithBias Herite des attributs et des méthodes de MovieLensModel\n",
        "class MovieLensModelWithBias(MovieLensModel):\n",
        "\n",
        "  def __init__(self, embedding_dimension, id_uniques, films_unique, task, min_vote=1, max_vote=5, user_dropout=0.3, movie_dropout=0.6):\n",
        "    super().__init__(embedding_dimension, id_uniques, films_unique, task)\n",
        "\n",
        "    self.min_vote, self.max_vote = min_vote, max_vote\n",
        "\n",
        "    # Cette couche plonge dans un espace de dimension 1. Sa sortie est une constante qui représente le biais utilisateur.\n",
        "    self.user_bias = user_model = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=id_uniques, mask_token=None),\n",
        "                                    tf.keras.layers.Embedding(len(id_uniques) + 1, 1)], name=\"User_Bias\")\n",
        "\n",
        "    self.movie_bias = user_model = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=films_unique, mask_token=None),\n",
        "                                    tf.keras.layers.Embedding(len(films_unique) + 1, 1)], name=\"Movie_Bias\")\n",
        "        \n",
        "    self.user_dropout  = tf.keras.layers.Dropout(rate = user_dropout, name=\"User_Dropout\")\n",
        "    self.movie_dropout = tf.keras.layers.Dropout(rate = movie_dropout, name=\"Movie_Dropout\")\n",
        "\n",
        "\n",
        "  def call(self, features):\n",
        "    user_embedding, movie_embedding = self.user_model(features[\"user_id\"]), self.movie_model(features[\"movie_title\"]) ## User-item extraction\n",
        "    user_bias, movie_bias = self.user_bias(features[\"user_id\"]), self.movie_bias(features[\"movie_title\"]) ## Bias extraction\n",
        "    \n",
        "    user_embedding = self.user_dropout(user_embedding) ## User dropout\n",
        "    movie_embedding = self.movie_dropout(movie_embedding) ## Item dropout\n",
        "\n",
        "    user_item_product = self.pred([user_embedding,movie_embedding]) ## Dot product of the dropouts\n",
        "    \n",
        "    votes_predictions = tf.math.sigmoid(user_bias + movie_bias + user_item_product) * (self.max_vote - self.min_vote) + self.min_vote\n",
        "\n",
        "    return votes_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "83ADzoELml6x",
        "outputId": "ed478032-37a9-4353-c2a6-91276d052025"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"movie_lens_model_with_bias\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " User_Embedding (Sequential)  (8192, 32)               30208     \n",
            "                                                                 \n",
            " Movie_Embedding (Sequential  (8192, 32)               53856     \n",
            " )                                                               \n",
            "                                                                 \n",
            " dot_1 (Dot)                 multiple                  0         \n",
            "                                                                 \n",
            " ranking (Ranking)           multiple                  0         \n",
            "                                                                 \n",
            " User_Bias (Sequential)      (8192, 1)                 944       \n",
            "                                                                 \n",
            " Movie_Bias (Sequential)     (8192, 1)                 1683      \n",
            "                                                                 \n",
            " User_Dropout (Dropout)      multiple                  0         \n",
            "                                                                 \n",
            " Movie_Dropout (Dropout)     multiple                  0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 86,691\n",
            "Trainable params: 86,691\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Initialisez le modèle et afficher ses couches (summary)\n",
        "Model_Bias = MovieLensModelWithBias(embedding_dimension, id_uniques, films_unique, task, min_vote=1, max_vote=5, user_dropout=0.3, movie_dropout=0.6)\n",
        "Model_Bias(feature)\n",
        "Model_Bias.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DV9_n_jKm97A"
      },
      "outputs": [],
      "source": [
        "# Compilez le modèle en ajoutant l'optimiseur Adam\n",
        "# Création du dossier contenant les modèles entrainés\n",
        "#!mkdir Models/\n",
        "\n",
        "# Compiler le modèle en ajoutant l'optimiseur Adam\n",
        "Model_Bias.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005))\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "slPoB57hnAUi",
        "outputId": "14635cef-34d3-4d18-e115-f1720d70d437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "10/10 [==============================] - 9s 546ms/step - root_mean_squared_error: 1.2274 - loss: 1.4965 - regularization_loss: 0.0000e+00 - total_loss: 1.4965 - val_root_mean_squared_error: 1.1936 - val_loss: 1.3926 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.3926\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 10s 529ms/step - root_mean_squared_error: 1.1791 - loss: 1.3801 - regularization_loss: 0.0000e+00 - total_loss: 1.3801 - val_root_mean_squared_error: 1.1497 - val_loss: 1.2896 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.2896\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 8s 530ms/step - root_mean_squared_error: 1.1190 - loss: 1.2402 - regularization_loss: 0.0000e+00 - total_loss: 1.2402 - val_root_mean_squared_error: 1.0907 - val_loss: 1.1577 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.1577\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 8s 534ms/step - root_mean_squared_error: 1.0396 - loss: 1.0688 - regularization_loss: 0.0000e+00 - total_loss: 1.0688 - val_root_mean_squared_error: 1.0238 - val_loss: 1.0174 - val_regularization_loss: 0.0000e+00 - val_total_loss: 1.0174\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 8s 534ms/step - root_mean_squared_error: 0.9634 - loss: 0.9197 - regularization_loss: 0.0000e+00 - total_loss: 0.9197 - val_root_mean_squared_error: 0.9785 - val_loss: 0.9292 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.9292\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 8s 537ms/step - root_mean_squared_error: 0.9134 - loss: 0.8281 - regularization_loss: 0.0000e+00 - total_loss: 0.8281 - val_root_mean_squared_error: 0.9570 - val_loss: 0.8899 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8899\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 8s 526ms/step - root_mean_squared_error: 0.8772 - loss: 0.7634 - regularization_loss: 0.0000e+00 - total_loss: 0.7634 - val_root_mean_squared_error: 0.9434 - val_loss: 0.8660 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8660\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 8s 536ms/step - root_mean_squared_error: 0.8447 - loss: 0.7075 - regularization_loss: 0.0000e+00 - total_loss: 0.7075 - val_root_mean_squared_error: 0.9346 - val_loss: 0.8507 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8507\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 9s 608ms/step - root_mean_squared_error: 0.8156 - loss: 0.6590 - regularization_loss: 0.0000e+00 - total_loss: 0.6590 - val_root_mean_squared_error: 0.9297 - val_loss: 0.8424 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8424\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 8s 525ms/step - root_mean_squared_error: 0.7892 - loss: 0.6164 - regularization_loss: 0.0000e+00 - total_loss: 0.6164 - val_root_mean_squared_error: 0.9277 - val_loss: 0.8391 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8391\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 9s 550ms/step - root_mean_squared_error: 0.7646 - loss: 0.5780 - regularization_loss: 0.0000e+00 - total_loss: 0.5780 - val_root_mean_squared_error: 0.9278 - val_loss: 0.8398 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8398\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 8s 527ms/step - root_mean_squared_error: 0.7415 - loss: 0.5430 - regularization_loss: 0.0000e+00 - total_loss: 0.5430 - val_root_mean_squared_error: 0.9295 - val_loss: 0.8434 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8434\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 8s 528ms/step - root_mean_squared_error: 0.7197 - loss: 0.5110 - regularization_loss: 0.0000e+00 - total_loss: 0.5110 - val_root_mean_squared_error: 0.9324 - val_loss: 0.8492 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.8492\n"
          ]
        }
      ],
      "source": [
        "#Entrainez le modèle\n",
        "history_TwoTowers_Model_Bias = Model_Bias.fit(train, epochs=15, validation_data=valid, callbacks=my_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "K8jgK6TUnBvu",
        "outputId": "99921423-d5be-474e-9b3f-1a244c62e002"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Best RMSE on validation : 0.9277\n"
          ]
        }
      ],
      "source": [
        "#Affichez les résultats\n",
        "def plot_history(history, model_name=\"Two Towers\"):\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['root_mean_squared_error'])\n",
        "    plt.plot(history.history['val_root_mean_squared_error'])\n",
        "    plt.title(model_name + ' Model RMSE')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.show()\n",
        "    print(\"\\n\\nBest RMSE on validation : {0:.4f}\".format(min(history.history['val_root_mean_squared_error'])))\n",
        "\n",
        "plot_history(history_TwoTowers_Model_Bias, model_name=\"Two Towers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4D0V1wgiaB6"
      },
      "source": [
        "#### Observations\n",
        "\n",
        "<u>Réponse</u> :<br>\n",
        "\n",
        "We can see that the RMSE of the training set is considerably lower. We got a RMSE of 0.7129 after 14 epochs using the new methods that includes the bias, while we got 0.8549 in the previous method. For the validation sets, we also got a better result, even though not as marked: 0.9253 for the bias method, and 0.9336 for the previous method. For the divergence between the RMSE of the train and test validations, we can identify that our model is efficient, but is overfitting. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p4rXQGoOQJp"
      },
      "source": [
        "## Question 3 (20 pts)\n",
        "Dans cette question, nous cherchons à améliorer le modèle Two Towers avec les biais de la question 2. <br> \n",
        "\n",
        "Voici quelques idées d'améliorations : "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjXxt35mEAna"
      },
      "source": [
        "### Question 3.1 (10 pts)\n",
        "\n",
        "Améliorez les performances en changeant les hyperparamètres du modèle (<i>dropout, embedding_dim, learning rate, etc...</i>). Quelle est l'impact de ces hyperparamètres sur le surapprentissage (<i>overfitting</i>) ? **(10 pts)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgxvThAaEDdn",
        "outputId": "dea15c08-bb1d-41eb-a8b7-707033365cb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lowest RMSE found is 0.9228752851486206, with user dropout of 0.1 and movie dropout of 0.1\n"
          ]
        }
      ],
      "source": [
        "## Trying different dropouts\n",
        "def test_dropouts():\n",
        "  user_dropouts = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "  movie_dropouts = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "  min_rmse = float('inf')\n",
        "  best_user_dropout = 0\n",
        "  best_movie_dropout = 0\n",
        "\n",
        "  for i in user_dropouts:\n",
        "    for j in movie_dropouts:\n",
        "      test_model = MovieLensModelWithBias(embedding_dimension, id_uniques, films_unique, task, min_vote=1, max_vote=5, user_dropout=i, movie_dropout=j)\n",
        "      test_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005))\n",
        "      history_model = test_model.fit(train, epochs=15, validation_data=valid, callbacks=my_callbacks, verbose=0)\n",
        "      if (min(history_model.history['val_root_mean_squared_error'])) < min_rmse:\n",
        "        min_rmse = min(history_model.history['val_root_mean_squared_error'])\n",
        "        best_user_dropout = i\n",
        "        best_movie_dropout = j\n",
        "  \n",
        "  print(\"The lowest RMSE found is {}, with user dropout of {} and movie dropout of {}\".format(min_rmse, best_user_dropout, best_movie_dropout))\n",
        "  \n",
        "test_dropouts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Trying different embedding dimensions, using dropout 0.1\n",
        "def test_dims():\n",
        "  embedding_dims = [2,4,8,16,32,64,128,256]\n",
        "  min_rmse = float('inf')\n",
        "  best_dim = 0\n",
        "\n",
        "  for i in embedding_dims:\n",
        "    test_model = MovieLensModelWithBias(i, id_uniques, films_unique, task, min_vote=1, max_vote=5, user_dropout=0.1, movie_dropout=0.1)\n",
        "    test_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005))\n",
        "    history_model = test_model.fit(train, epochs=15, validation_data=valid, callbacks=my_callbacks, verbose=0)\n",
        "    if (min(history_model.history['val_root_mean_squared_error'])) < min_rmse:\n",
        "      min_rmse = min(history_model.history['val_root_mean_squared_error'])\n",
        "      best_dim = i\n",
        "  \n",
        "  print(\"The lowest RMSE found is {}, with embedding dimension of {}\".format(min_rmse, best_dim))\n",
        "  \n",
        "test_dims()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM-BbEyDgvgt",
        "outputId": "0d2790ef-e7a8-47ff-b3bb-b718a35a8153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lowest RMSE found is 0.9246339201927185, with embedding dimension of 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Trying different learning rates, using dropout 0.1 and embedding dimension 32\n",
        "def test_learning_rates():\n",
        "  learning_rates = [0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001]\n",
        "  min_rmse = float('inf')\n",
        "  best_rate = 0\n",
        "\n",
        "  for i in learning_rates:\n",
        "    test_model = MovieLensModelWithBias(embedding_dimension, id_uniques, films_unique, task, min_vote=1, max_vote=5, user_dropout=0.1, movie_dropout=0.1)\n",
        "    test_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=i))\n",
        "    history_model = test_model.fit(train, epochs=15, validation_data=valid, callbacks=my_callbacks, verbose=0)\n",
        "    if (min(history_model.history['val_root_mean_squared_error'])) < min_rmse:\n",
        "      min_rmse = min(history_model.history['val_root_mean_squared_error'])\n",
        "      best_rate = i\n",
        "  \n",
        "  print(\"The lowest RMSE found is {}, with learning rate of {}\".format(min_rmse, best_rate))\n",
        "  \n",
        "test_learning_rates()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMuB4h9q9MqU",
        "outputId": "013c0e1f-0cdd-46db-d824-6a06e5e7bfc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The lowest RMSE found is 0.9266558885574341, with learning rate of 0.005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAH7M7HTEF34"
      },
      "source": [
        "### Question 3.2 (10 pts)\n",
        "\n",
        "Commencez l'entrainement du modèle avec des plongements pré-entrainés (pretrained embeddings) obtenus aux questions précédentes. **(10 pts)**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Based on the code given in https://www.tensorflow.org/recommenders/examples/featurization\n",
        "## And in https://www.tensorflow.org/recommenders/examples/context_features \n",
        "\n",
        "## Getting datasets of movie titles, user ids and timestamps\n",
        "ratings = votes.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "    \"timestamp\": x[\"timestamp\"],\n",
        "})\n",
        "movies = films.map(lambda x: x[\"movie_title\"])\n",
        "\n",
        "timestamps = np.concatenate(list(ratings.map(lambda x: x[\"timestamp\"]).batch(100)))\n",
        "\n",
        "max_timestamp = timestamps.max()\n",
        "min_timestamp = timestamps.min()\n",
        "\n",
        "timestamp_buckets = np.linspace(\n",
        "    min_timestamp, max_timestamp, num=1000,\n",
        ")\n",
        "\n",
        "unique_movie_titles = np.unique(np.concatenate(list(movies.batch(1000))))\n",
        "unique_user_ids = np.unique(np.concatenate(list(ratings.batch(1_000).map(\n",
        "    lambda x: x[\"user_id\"]))))"
      ],
      "metadata": {
        "id": "s4rD5RPpIQw3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Builds a user model class, containing the embeddings of unique user ids, and \n",
        "## Embeddings of timestamps\n",
        "class UserModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, use_timestamps):\n",
        "    super().__init__()\n",
        "\n",
        "    self._use_timestamps = use_timestamps\n",
        "\n",
        "    self.user_embedding = tf.keras.Sequential([\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=unique_user_ids, mask_token=None),\n",
        "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
        "    ])\n",
        "\n",
        "    if use_timestamps:\n",
        "      self.timestamp_embedding = tf.keras.Sequential([\n",
        "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
        "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
        "      ])\n",
        "      self.normalized_timestamp = tf.keras.layers.Normalization(\n",
        "          axis=None\n",
        "      )\n",
        "\n",
        "      self.normalized_timestamp.adapt(timestamps)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    if not self._use_timestamps:\n",
        "      return self.user_embedding(inputs[\"user_id\"])\n",
        "\n",
        "    return tf.concat([\n",
        "        self.user_embedding(inputs[\"user_id\"]),\n",
        "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
        "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
        "    ], axis=1)"
      ],
      "metadata": {
        "id": "tIY6WLeoKalR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Builds a movie model class, containing the embeddings of unique movie titles\n",
        "class MovieModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    max_tokens = 10_000\n",
        "\n",
        "    self.title_embedding = tf.keras.Sequential([\n",
        "      tf.keras.layers.StringLookup(\n",
        "          vocabulary=unique_movie_titles, mask_token=None),\n",
        "      tf.keras.layers.Embedding(len(unique_movie_titles) + 1, 32)\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer = tf.keras.layers.TextVectorization(\n",
        "        max_tokens=max_tokens)\n",
        "\n",
        "    self.title_text_embedding = tf.keras.Sequential([\n",
        "      self.title_vectorizer,\n",
        "      tf.keras.layers.Embedding(max_tokens, 32, mask_zero=True),\n",
        "      tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    ])\n",
        "\n",
        "    self.title_vectorizer.adapt(movies)\n",
        "\n",
        "  def call(self, titles):\n",
        "    return tf.concat([\n",
        "        self.title_embedding(titles),\n",
        "        self.title_text_embedding(titles),\n",
        "    ], axis=1)"
      ],
      "metadata": {
        "id": "clyvFuFoKidu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creates a unique model, mixing the two previous, and using the TP's given task as metrics\n",
        "class MovielensModel(tfrs.models.Model):\n",
        "\n",
        "  def __init__(self, use_timestamps):\n",
        "    super().__init__()\n",
        "    self.query_model = tf.keras.Sequential([\n",
        "      UserModel(use_timestamps),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.candidate_model = tf.keras.Sequential([\n",
        "      MovieModel(),\n",
        "      tf.keras.layers.Dense(32)\n",
        "    ])\n",
        "    self.task = task\n",
        "\n",
        "  def compute_loss(self, features, training=False):\n",
        "    # We only pass the user id and timestamp features into the query model. This\n",
        "    # is to ensure that the training inputs would have the same keys as the\n",
        "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
        "    # error when loading the query model after saving it.\n",
        "    query_embeddings = self.query_model({\n",
        "        \"user_id\": features[\"user_id\"],\n",
        "        \"timestamp\": features[\"timestamp\"],\n",
        "    })\n",
        "    movie_embeddings = self.candidate_model(features[\"movie_title\"])\n",
        "\n",
        "    return self.task(query_embeddings, movie_embeddings)"
      ],
      "metadata": {
        "id": "FN-ZTkQQKlPf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Trains the network, using the pre-trained embeddings, without timestamps\n",
        "\n",
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=3),\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "]\n",
        "\n",
        "model = MovielensModel(use_timestamps=False)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "history = model.fit(train, epochs=15, validation_data=valid, callbacks=my_callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nreuEX6Kobh",
        "outputId": "5ee28343-ea91-426a-ebf3-806e742a5d6b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            " 9/10 [==========================>...] - ETA: 0s - root_mean_squared_error: 0.0437 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "10/10 [==============================] - 7s 391ms/step - root_mean_squared_error: 0.0437 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0437 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 6s 374ms/step - root_mean_squared_error: 0.0436 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0436 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 6s 371ms/step - root_mean_squared_error: 0.0436 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0436 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 6s 371ms/step - root_mean_squared_error: 0.0435 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0436 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 6s 376ms/step - root_mean_squared_error: 0.0435 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0435 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 6s 378ms/step - root_mean_squared_error: 0.0434 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0435 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 6s 377ms/step - root_mean_squared_error: 0.0434 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0434 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 6s 381ms/step - root_mean_squared_error: 0.0434 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0434 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 6s 378ms/step - root_mean_squared_error: 0.0433 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0434 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 6s 377ms/step - root_mean_squared_error: 0.0433 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0433 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 6s 380ms/step - root_mean_squared_error: 0.0432 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0433 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 6s 376ms/step - root_mean_squared_error: 0.0432 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0433 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 6s 396ms/step - root_mean_squared_error: 0.0432 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0432 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 6s 372ms/step - root_mean_squared_error: 0.0431 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0432 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 6s 366ms/step - root_mean_squared_error: 0.0431 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019 - val_root_mean_squared_error: 0.0432 - val_loss: 0.0019 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-OnVMmiJ7to"
      },
      "source": [
        "### Bonus (10 pts)\n",
        "\n",
        "Prenez en compte les `timestamps`, ou développez d'autres idées que vous détaillerez."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Running the previous model, now considering the timestamps:\n",
        "model = MovielensModel(use_timestamps=True)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
        "\n",
        "history = model.fit(train, epochs=15, validation_data=valid, callbacks=my_callbacks)"
      ],
      "metadata": {
        "id": "Gvi7dwce9AQQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52989910-5815-4e74-d1c4-4744b957b151"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            " 9/10 [==========================>...] - ETA: 0s - root_mean_squared_error: 0.1333 - loss: 0.0178 - regularization_loss: 0.0000e+00 - total_loss: 0.0178WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'user_id': <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=string>, 'timestamp': <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=float32>}. Consider rewriting this model with the Functional API.\n",
            "10/10 [==============================] - 7s 396ms/step - root_mean_squared_error: 0.1324 - loss: 0.0172 - regularization_loss: 0.0000e+00 - total_loss: 0.0172 - val_root_mean_squared_error: 0.1213 - val_loss: 0.0146 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0146\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - 6s 385ms/step - root_mean_squared_error: 0.1119 - loss: 0.0123 - regularization_loss: 0.0000e+00 - total_loss: 0.0123 - val_root_mean_squared_error: 0.1031 - val_loss: 0.0106 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0106\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - 6s 392ms/step - root_mean_squared_error: 0.0957 - loss: 0.0090 - regularization_loss: 0.0000e+00 - total_loss: 0.0090 - val_root_mean_squared_error: 0.0888 - val_loss: 0.0078 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0078\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - 6s 384ms/step - root_mean_squared_error: 0.0830 - loss: 0.0068 - regularization_loss: 0.0000e+00 - total_loss: 0.0068 - val_root_mean_squared_error: 0.0777 - val_loss: 0.0060 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0060\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - 6s 371ms/step - root_mean_squared_error: 0.0732 - loss: 0.0053 - regularization_loss: 0.0000e+00 - total_loss: 0.0053 - val_root_mean_squared_error: 0.0692 - val_loss: 0.0048 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0048\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - 6s 379ms/step - root_mean_squared_error: 0.0658 - loss: 0.0043 - regularization_loss: 0.0000e+00 - total_loss: 0.0043 - val_root_mean_squared_error: 0.0628 - val_loss: 0.0039 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0039\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - 6s 380ms/step - root_mean_squared_error: 0.0602 - loss: 0.0036 - regularization_loss: 0.0000e+00 - total_loss: 0.0036 - val_root_mean_squared_error: 0.0581 - val_loss: 0.0034 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0034\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - 6s 406ms/step - root_mean_squared_error: 0.0561 - loss: 0.0031 - regularization_loss: 0.0000e+00 - total_loss: 0.0031 - val_root_mean_squared_error: 0.0546 - val_loss: 0.0030 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0030\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - 6s 393ms/step - root_mean_squared_error: 0.0532 - loss: 0.0028 - regularization_loss: 0.0000e+00 - total_loss: 0.0028 - val_root_mean_squared_error: 0.0522 - val_loss: 0.0027 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0027\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - 6s 397ms/step - root_mean_squared_error: 0.0511 - loss: 0.0026 - regularization_loss: 0.0000e+00 - total_loss: 0.0026 - val_root_mean_squared_error: 0.0504 - val_loss: 0.0025 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0025\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - 6s 402ms/step - root_mean_squared_error: 0.0496 - loss: 0.0025 - regularization_loss: 0.0000e+00 - total_loss: 0.0025 - val_root_mean_squared_error: 0.0492 - val_loss: 0.0024 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0024\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - 6s 403ms/step - root_mean_squared_error: 0.0486 - loss: 0.0024 - regularization_loss: 0.0000e+00 - total_loss: 0.0024 - val_root_mean_squared_error: 0.0483 - val_loss: 0.0023 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0023\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - 6s 378ms/step - root_mean_squared_error: 0.0479 - loss: 0.0023 - regularization_loss: 0.0000e+00 - total_loss: 0.0023 - val_root_mean_squared_error: 0.0477 - val_loss: 0.0023 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0023\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - 6s 386ms/step - root_mean_squared_error: 0.0474 - loss: 0.0022 - regularization_loss: 0.0000e+00 - total_loss: 0.0022 - val_root_mean_squared_error: 0.0473 - val_loss: 0.0022 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0022\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - 6s 383ms/step - root_mean_squared_error: 0.0470 - loss: 0.0022 - regularization_loss: 0.0000e+00 - total_loss: 0.0022 - val_root_mean_squared_error: 0.0470 - val_loss: 0.0022 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.0022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFtv1UQ_7f1d"
      },
      "source": [
        "## Question 4 (50 points)\n",
        "\n",
        "Maintenant que vous vous êtes familiarisés avec les librairies de `Tensorflow`, attaquons-nous à l'état de l'art. En utilisant des mots-clés comme `Deep Learning`, `Recommender Systems`, et `MovieLens`, faites une brève revue de l'état de l'art. Il est impératif que vous <b>citiez vos [sources](https://ulyngs.github.io/oxforddown/cites-and-refs.html)</b>.\n",
        "\n",
        "Ensuite, inspirez-vous de vos recherches pour proposer une approche plus performante que celle vue au-dessus. Pour cette question, il est recommandé de fournir un rapport séparé pour votre état de l'art et l'explication de votre démarche en format PDF. Mais, si vous ne souhaitez pas rédiger de rapport, vous pouvez rédiger dans les cellules textes ci-dessous.\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Cette question vous laisse beaucoup de liberté dans vos réponses, vous pouvez utiliser n'importe quelle bibliothèque Python contrairement aux autres questions. Néanmoins, vous êtes quand même **soumis à des contraintes** :\n",
        "- Vous devez utiliser uniquement les données `MovieLens 100k`\n",
        "- **Si** vous **n**'avez **pas** besoin de features supplémentaires de `Movielens 100k` que celle extraite dans la **question 1.1**, utilisez l'ensemble d'entrainement (`train`) et de validation (`valid`) créée à la question 1.5\n",
        "- Votre modèle doit se baser sur des réseaux de neurones\n",
        "- Votre modèle doit être en tensorflow\n",
        "- Vous **ne** pouvez **pas** **entrainer** vos modèles sur les données de **validation** \n",
        "- Citez obligatoirement vos sources !\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "Une approche possible qu'on vous propose est de **réimplémenter** la méthode décrite dans le papier [Scalable deep learning-based recommendation systems](https://www.sciencedirect.com/science/article/pii/S2405959518302029) de H. Lee et al.<br>\n",
        "\n",
        "Pour cela il faut :\n",
        "1. Créer la matrice utilisateur-item\n",
        "2. Implémenter leur preprocessing sur la matrice utilisateur-item\n",
        "3. Implémenter le modèle décrit pour `MovieLens 100k`\n",
        "4. Entrainer le modèle\n",
        "5. Comparer les résultats obtenus en calculant la RMSE sur l'ensemble de validation par rapport à ceux obtenus par les méthodes précédentes\n",
        "\n",
        "<br><br>\n",
        "\n",
        "\n",
        "<big><b><center>Les 3 groupes ayant les meilleurs RMSE sur l'ensemble de validation auront 10 points de bonus.</center></b></big>\n",
        "\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "\n",
        "**Qualités attendues du travail**, vous serez noté selon :\n",
        "- L'originalité de votre démarche\n",
        "- La cohérence de votre démarche avec l'état de l'art rédigé\n",
        "- Les résultats empiriques (**RMSE**) sur l'ensemble de validation, notamment est-ce qu'elle performe mieux que les méthodes précédentes de manière consistante ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-AyqT3spxFI"
      },
      "source": [
        "#### État de l'art (15 points)\n",
        "\n",
        "\n",
        "\n",
        "<u>Réponse :</u><br>\n",
        "<i>Vous pouvez rédiger ici.</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ddey_xSp0uI"
      },
      "source": [
        "#### Code et démarche (35 points)\n",
        "\n",
        "##### Démarche et raisonnement :\n",
        "\n",
        "<ul>\n",
        "  <li>Citez vos sources qui vous aider à produire votre solution. En particulier, mentionnez la source du code que vous avez pris et modifié s'il y a lieu</li>\n",
        "  <li>Expliquez votre démarche et votre raisonnement.</li>\n",
        "</ul>\n",
        "\n",
        "\n",
        "<u>Réponse :</u><br>\n",
        "<i>Vous pouvez rédiger ici.</i>\n",
        "\n",
        "##### Code\n",
        "\n",
        "Faites en sorte que le code soit lisible et facilement interprétable."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Answer in the PDF file. "
      ],
      "metadata": {
        "id": "Wl2HHnCBCwoR"
      },
      "execution_count": 1,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "TP3_Squelette_Mine.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}